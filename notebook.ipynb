{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c20456",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8856b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Bank Customer Churn Prediction.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d0f1cf",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96561a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdc3612",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape  # 10000 rows(customer) and 12 columns (features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a154d75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48f5841",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c783cd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()  # no missing values in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265c3601",
   "metadata": {},
   "source": [
    "Although the original dataset had no missing values,\n",
    "I simulated missing data to reflect real-world scenarios\n",
    "and demonstrated how to handle them properly\n",
    "using median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7373192d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740d3d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here I will add some NANs to simulate missing values\n",
    "np.random.seed(42)\n",
    "\n",
    "for col in ['age', 'balance', 'estimated_salary']:\n",
    "    df.loc[df.sample(frac=0.05).index, col] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999b64a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3591c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values by filling them with the median of each column\n",
    "# (median is better for numerical data with outliers)\n",
    "\n",
    "df['age'].fillna(df['age'].median(), inplace=True)\n",
    "df['balance'].fillna(df['balance'].median(), inplace=True)\n",
    "df['estimated_salary'].fillna(df['estimated_salary'].median(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc892386",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()  # no missing values now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d2f728",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['churn'].value_counts()\n",
    "# 0 --> cutomer stayed, 1 --> customer left\n",
    "# imbalanced data (customer stayed >> customer left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd3c317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da80892e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='churn', data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb820d9a",
   "metadata": {},
   "source": [
    "### Numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90e6f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe() # statistical summary of numerical columns\n",
    "# --- Key Insight on Balance Column ---\n",
    "# 1. Mean (77.5k) is lower than Median (97.3k). \n",
    "# 2. This happens because the first 25% of customers have a 0.0 balance (Min and 25% are both 0).\n",
    "# 3. These \"Zero-balance\" customers act as outliers that pull the average (Mean) down."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d107f6",
   "metadata": {},
   "source": [
    "As we can see here, the Median(50%) is higher than the Mean, which indicates a Left-Skewed distribution of non-zero balances, heavily influenced by the 25% of customers with zero balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0493e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df['age'], bins=30)\n",
    "plt.show()\n",
    "sns.histplot(df['balance'], bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de012e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='churn', y='age', data=df) # boxplot to see age distribution of cutomers that left vs stayed\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8248f2a5",
   "metadata": {},
   "source": [
    "### categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc08adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff8d76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='country', hue='churn', data=df)\n",
    "plt.show()\n",
    "# --- Key Insight on Country vs Churn ---\n",
    "# 1. France has the largest customer base (blue bars) among the three countries.\n",
    "# 2. Germany shows a significantly higher \"churn rate\" (the orange bar is almost half the blue bar).\n",
    "# 3. Spain appears to be the most stable market with the lowest churn numbers.\n",
    "# 4. customers in Germany are leaving at a higher percentage compared to France and Spain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803dea1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='gender', hue='churn', data=df)\n",
    "plt.show()\n",
    "# --- Key Insight on Gender vs Churn ---\n",
    "# 1. The customer base is almost evenly split between males and females.\n",
    "# 2. However, females show a slightly higher churn rate compared to males.\n",
    "# 3. This could indicate that female customers are more likely to leave the bank than male customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1761c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc07a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='active_member', hue='churn', data=df)\n",
    "plt.show()\n",
    "# --- Key Insight on Active Member vs Churn ---\n",
    "# 1. Active members (blue bars) are significantly more likely to stay with the bank\n",
    "# 2. Inactive members (orange bars) show a much higher churn rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae43508f",
   "metadata": {},
   "source": [
    "### correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9387422",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric = df.select_dtypes(include=['int64', 'float64'])\n",
    "# here I used only the numerical columns for correlation heatmap and excluded categorical columns\n",
    "# I kept the categorical columns as they are during the EDA phase (didn't encode it) \n",
    "# to ensure that visualizations and insights remain human-readable .\n",
    "# This helps in avoiding \"Data Leakage\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28523642",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(df_numeric.corr(), annot=True, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930b94ad",
   "metadata": {},
   "source": [
    "# data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cc3ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('customer_id', axis=1, inplace=True)\n",
    "# dropping customer_id as it is not useful for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94646a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('churn', axis=1)\n",
    "y = df['churn']\n",
    "# Features and target variable separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6aea00",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.select_dtypes(include='object').columns\n",
    "# Categorical columns that need encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ef71e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X, drop_first=True)\n",
    "# I used drop_first=True to avoid the Dummy Variable Trap.\n",
    "# It removes redundant information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c4b46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()\n",
    "#here we dropped france as the first column \n",
    "# so if it is false at spain and germany then it's true at france \n",
    "# and also we dropped the female gender column as if it's false at male then it's true at female\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3234e2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa8e010",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "#I used StandardScaler to ensure that all features are on the same scale.\n",
    "# This prevents features with large values (like Salary) from dominating the model\n",
    "# and helps algorithms like Logistic Regression or SVM to converge faster and perform better\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba7a689",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split\n",
    "(\n",
    "    X_scaled, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "#I split the data into 80% training and 20% testing\n",
    "# I used \"stratify=y\" to ensure that both sets have the same proportion \n",
    "# of classes as the original dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe1c296",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape\n",
    "# the train rows took 8000 from the total 10000 rows which is 80%  \n",
    "# the column numbers is the same in the train and test sets as the model should \n",
    "# learn on the same features during training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33072952",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape\n",
    "# the test rows took 2000 from the total 10000 rows which is 20%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972a624b",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd038096",
   "metadata": {},
   "source": [
    "### logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08cda8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_model = LogisticRegression(max_iter=1000)\n",
    "log_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef681c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_log = log_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7526fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_log))\n",
    "print(classification_report(y_test, y_pred_log))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27eb668b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ca72ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cff98a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcab92d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb_model = GradientBoostingClassifier(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_gb))\n",
    "print(classification_report(y_test, y_pred_gb))\n",
    "\n",
    "\n",
    "# I was going to use XGBoost but it caused memory issues on my system.\n",
    "# So instead I used Gradient Boosting improves prediction accuracy by\n",
    "# sequentially correcting errors made by previous models,\n",
    "# making it more robust than single estimators.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724c8411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the Confusion Matrix for Gradient Boosting Model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_gb)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix - Gradient Boosting\")\n",
    "plt.show()\n",
    "\n",
    "#The most critical error is predicting a churned customer as non-churned\n",
    "#because the company loses the opportunity to take preventive action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da81882d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "importance = gb_model.feature_importances_\n",
    "features = X.columns\n",
    "\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': importance\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "feature_importance_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64a9bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(\n",
    "    x='Importance',\n",
    "    y='Feature',\n",
    "    data=feature_importance_df.head(10)\n",
    ")\n",
    "plt.title(\"Top Features Affecting Customer Churn\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115599d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(gb_model, \"gradient_boosting_churn_model.pkl\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "\n",
    "#I saved the trained model and scaler to ensure\n",
    "#consistent preprocessing during deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4acae7d",
   "metadata": {},
   "source": [
    "### Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20bea14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import joblib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bba41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and scaler\n",
    "model = joblib.load(\"gradient_boosting_churn_model.pkl\")\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "\n",
    "st.title(\"Customer Churn Prediction App\")\n",
    "\n",
    "st.write(\"Enter customer details to predict churn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02ec1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "age = st.number_input(\"Age\", 18, 100)\n",
    "balance = st.number_input(\"Balance\")\n",
    "credit_score = st.number_input(\"Credit Score\", 300, 900)\n",
    "products = st.number_input(\"Number of Products\", 1, 4)\n",
    "is_active = st.selectbox(\"Is Active Member?\", [0, 1])\n",
    "salary = st.number_input(\"Estimated Salary\")\n",
    "\n",
    "if st.button(\"Predict Churn\"):\n",
    "    data = np.array([[credit_score, age, balance, products, is_active, salary]])\n",
    "    data = scaler.transform(data)\n",
    "\n",
    "    prediction = model.predict(data)\n",
    "\n",
    "    if prediction[0] == 1:\n",
    "        st.error(\"⚠️ Customer is likely to churn\")\n",
    "    else:\n",
    "        st.success(\"✅ Customer is likely to stay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef1756e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a5b07a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "churn_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
